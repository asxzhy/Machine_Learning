{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using Health Record Data to Detect Heart Failure with SageMaker Feature Store**\n",
    "\n",
    "This notebook runs with Kernel Python 3 (Data Science).\n",
    "\n",
    "Note: These policy must be attached to the execution role of the AmazonSageMaker Studio\n",
    "- AmazonSageMakerFullAccess\n",
    "- AmazonSageMakerFeatureStoreAccess\n",
    "- AmazonS3FullAccess\n",
    "\n",
    "## **Check policy:**\n",
    "1. Copy your `execution role name`\n",
    "2. Go to Servise `IAM`\n",
    "3. Select `Roles` under `Access management`\n",
    "4. Search the role name copied and check list under `policy name`\n",
    "5. Use `Attach policies` if needed\n",
    "\n",
    "## **Terminology:**\n",
    "- `Feature Group` - A FeatureGroup is the main Feature Store resource that contains the metadata for all the data stored in Amazon SageMaker Feature Store. A FeatureGroup is a logical grouping of features, defined in the feature store, to describe record. A FeatureGroup's definition is composed of a list of feature definitions, a record identifier name, and configurations for its online and offline store.\n",
    "- `Feature definition` - A FeatureDefinition consists of a name and one of the following data types: an Integral, String or Fractional. A FeatureGroup contains a list of feature definitions.\n",
    "- `Record identifier name` - Each feature group is defined with a record identifier name. The record identifier name must refer to one of the names of a feature defined in the feature group's feature definitions.\n",
    "- `Event time` - A point in time when a new event occurs that corresponds to the creation or update of a record in a feature group. All records in the feature group must have a corresponding Eventtime. It can be used to track changes to a record over time. The online store contains the record corresponding to the last Eventtime for a record identifier name, whereas the offline store contains all historic records.\n",
    "- `Online store` - The low latency, high availability cache for a feature group that enables real-time lookup of records. The online store allows quick access to the latest value for a Record via the GetRecord API. A feature group contains an OnlineStoreConfig controlling where the data is stored.\n",
    "- `Offline store` - The OfflineStore, stores historical data in your S3 bucket. It is used when low (sub-second) latency reads are not needed. For example, when you want to store and serve features for exploration, model training, and batch inference. A feature group contains and OfflineStoreConfig controlling where the data is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup SageMaker FeatureStore\n",
    "Start with setting up the SageMaker Python SDK and boto client\n",
    "\n",
    "`boto3` -  A AWS SDK for Python for creating, configuring, and managing AWS services.\n",
    "\n",
    "`sagemaker.session.Session()` - https://sagemaker.readthedocs.io/en/stable/api/utility/session.html &\n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html#module-boto3.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# the default region when creating new connections. Returns us-east-2\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# create a session\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "# create a service client\n",
    "# param: servise_name - the name of a service\n",
    "# param: region_name - the name of the region associated with the client\n",
    "# can get a list of available services via get_available_services()\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "# initialize a SageMaker Session\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up IAM Role\n",
    "`sagemaker.get_execution_role()` - Return the role ARN whose credentials are used to call the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::773441300604:role/service-role/AmazonSageMaker-ExecutionRole-20211102T144581\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up S3 Bucket For The Offline Store\n",
    "SageMaker FeatureStore writes the data in the `OfflineStore` of a `FeatureGroup` to a S3 bucket owned by you. To be able to write to your S3 bucket, SageMaker FeatureStore assumes an IAM role which has access to the bucket. the role is also owned by you. Note that the same bucket can be re-used across `FeatureGroups`. Data in the bucket is partitioned by Feature Group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-2-773441300604\n"
     ]
    }
   ],
   "source": [
    "# the default Amazon S3 bucket to be used by this session\n",
    "default_s3_bucket_name = feature_store_session.default_bucket()\n",
    "prefix = 'feature_store_demo'\n",
    "print(default_s3_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Dataset\n",
    "This demo will use the [Heart Failure Medical Record Dataset](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records)\n",
    "\n",
    "`IPython.dislpay.display()` - https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-02 18:48:35--  https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12239 (12K) [application/x-httpd-php]\n",
      "Saving to: ‘data/clinical_records_dataset.csv’\n",
      "\n",
      "data/clinical_recor 100%[===================>]  11.95K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-02 18:48:35 (217 MB/s) - ‘data/clinical_records_dataset.csv’ saved [12239/12239]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv -O data/clinical_records_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/clinical_records_dataset.csv to s3://sagemaker-us-east-2-773441300604/feature_store_demo/data/clinical_records_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# upload data to s3 bucket\n",
    "!aws s3 cp ./data/clinical_records_dataset.csv s3://$default_s3_bucket_name/$prefix/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data_file_name = 'clinical_records_dataset.csv'\n",
    "# this is the path to get the data in the s3 bucket\n",
    "clinical_data_path = \"s3://{}/{}/data/{}\".format(default_s3_bucket_name, prefix, clinical_data_file_name)\n",
    "# use the data path to retrieve the data\n",
    "clinical_df = pd.read_csv(clinical_data_path)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "clinical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of the value missing in each column is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                         0.0\n",
       "anaemia                     0.0\n",
       "creatinine_phosphokinase    0.0\n",
       "diabetes                    0.0\n",
       "ejection_fraction           0.0\n",
       "high_blood_pressure         0.0\n",
       "platelets                   0.0\n",
       "serum_creatinine            0.0\n",
       "serum_sodium                0.0\n",
       "sex                         0.0\n",
       "smoking                     0.0\n",
       "time                        0.0\n",
       "DEATH_EVENT                 0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is data missing in the dataframe\n",
    "print('percentage of the value missing in each column is: ')\n",
    "\n",
    "clinical_df.isnull().sum() / len(clinical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we do not need to do any pre-processing because there is no missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for FeatureStore\n",
    "In the Amazon SageMaker Feature Store API, a feature is an attribute of a record. You can define a name and type for every feature stored in Feature Store. Name uniquely identifies a feature within a feature group. Type identifies the datatype for the values of the feature. Supported datatypes are: string, Integral and Fractional.\n",
    "\n",
    "Take a look at the data types and making sure they are all correct and readable by Feature Store. SageMaker Feature Store python SDK will map the string dtype to String feature type.\n",
    "\n",
    "In SageMaker Feature Store, a `record` is a collection of values for features for a single record identifier value. Specific features are flagged with record identifier and event time, and the combination of a record identifier name and a timestamp uniquely identify a record within a feature group. We will need to specify a record identifier and an event time in this case, and since the raw data does not contain these two columns, we will need to create them.\n",
    "\n",
    "- For record identifier name: a record is a collection of values for features for a single record identifier value. In this case, we will create an unique ID for each patient and use this as the record identifier.\n",
    "- For event time feature name: the event time refers to a point in the time when a new event occurred and corresponds to the creation or update of a record in a feature group. The event time can be used to track changes to a record over time. For example, in this use case, EventTime can be appended to your data when no timestamp is available. In the following code, you can see how EventTime is appended to the clinicla data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an unique ID for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unique patient id for each patient\n",
    "clinical_df.reset_index(inplace=True)\n",
    "clinical_df.rename(columns={'index': 'patient_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                    int64\n",
       "age                         float64\n",
       "anaemia                       int64\n",
       "creatinine_phosphokinase      int64\n",
       "diabetes                      int64\n",
       "ejection_fraction             int64\n",
       "high_blood_pressure           int64\n",
       "platelets                   float64\n",
       "serum_creatinine            float64\n",
       "serum_sodium                  int64\n",
       "sex                           int64\n",
       "smoking                       int64\n",
       "time                          int64\n",
       "DEATH_EVENT                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the types\n",
    "clinical_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want the unique id to be reated as a string ID not an integer\n",
    "clinical_df['patient_id'] = clinical_df['patient_id'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a TimeStamp for each Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.635879e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.635879e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.635879e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.635879e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.635879e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id   age  anaemia  creatinine_phosphokinase  diabetes  \\\n",
       "0          0  75.0        0                       582         0   \n",
       "1          1  55.0        0                      7861         0   \n",
       "2          2  65.0        0                       146         0   \n",
       "3          3  50.0        1                       111         0   \n",
       "4          4  65.0        1                       160         1   \n",
       "\n",
       "   ejection_fraction  high_blood_pressure  platelets  serum_creatinine  \\\n",
       "0                 20                    1  265000.00               1.9   \n",
       "1                 38                    0  263358.03               1.1   \n",
       "2                 20                    0  162000.00               1.3   \n",
       "3                 20                    0  210000.00               1.9   \n",
       "4                 20                    0  327000.00               2.7   \n",
       "\n",
       "   serum_sodium  sex  smoking  time  DEATH_EVENT    event_time  \n",
       "0           130    1        0     4            1  1.635879e+09  \n",
       "1           136    1        0     6            1  1.635879e+09  \n",
       "2           129    1        1     7            1  1.635879e+09  \n",
       "3           137    1        0     7            1  1.635879e+09  \n",
       "4           116    0        0     8            1  1.635879e+09  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append EventTime\n",
    "import time\n",
    "\n",
    "current_time_sec = int(round(time.time()))\n",
    "clinical_df['event_time'] = pd.Series([current_time_sec]*len(clinical_df), dtype='float64')\n",
    "\n",
    "clinical_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data types for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_object_to_string(df):\n",
    "    for label in df.columns:\n",
    "        if df.dtypes[label] == 'object':\n",
    "            df[label] = df[label].astype('str').astype('string')\n",
    "            \n",
    "# cast obkect to string\n",
    "# The SageMaker FeatureStore Python SDK will map the string dtype to String feature type\n",
    "# Other types like float and int will be mapped to fractional and integral\n",
    "cast_object_to_string(clinical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                   string\n",
       "age                         float64\n",
       "anaemia                       int64\n",
       "creatinine_phosphokinase      int64\n",
       "diabetes                      int64\n",
       "ejection_fraction             int64\n",
       "high_blood_pressure           int64\n",
       "platelets                   float64\n",
       "serum_creatinine            float64\n",
       "serum_sodium                  int64\n",
       "sex                           int64\n",
       "smoking                       int64\n",
       "time                          int64\n",
       "DEATH_EVENT                   int64\n",
       "event_time                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features\n",
    "In this step we will create the FeatureGroup representing the patients' medical record data, then ingest the data into the created FeatureGroup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign a feature group name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clinical-feature-group-02-18-50-36'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "clinical_feature_group_name = 'clinical-feature-group-' + strftime('%d-%H-%M-%S', gmtime())\n",
    "clinical_feature_group_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure a FeatureGroup\n",
    "\n",
    "`sagemaker.feature_store.feature_group.FeatureGroup` - https://sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html#sagemaker.feature_store.feature_group.FeatureGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "# This class instantiates a FeatureGroup object that comprises of a name for the FeatureGroup, \n",
    "# session instance, and a list of feature definition objects i.e., FeatureDefinition.\n",
    "clinical_feature_group = FeatureGroup(\n",
    "    name=clinical_feature_group_name, \n",
    "    sagemaker_session=feature_store_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Identifier\n",
    "In this step, we will specify the record identifier name and the event time feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record identifier and event time feature names\n",
    "record_identifier_feature_name = 'patient_id'\n",
    "event_time_feature_name = 'event_time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load feature definitions to the feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='patient_id', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='age', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='anaemia', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='creatinine_phosphokinase', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='diabetes', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='ejection_fraction', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='high_blood_pressure', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='platelets', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='serum_creatinine', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='serum_sodium', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='sex', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='smoking', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='time', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='DEATH_EVENT', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='event_time', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_feature_group.load_feature_definitions(data_frame=clinical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create FeatureGroup\n",
    "In this step, we will use the create function to create the feature group. Note that the online store is not created by default, se you must set this as `True` if you want to enable it. The `s3_url` is the S3 bucket location of your offline store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup clinical-feature-group-02-18-50-36 successfully created.\n"
     ]
    }
   ],
   "source": [
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get('FeatureGroupStatus')\n",
    "    while status == 'Creating':\n",
    "        print('Waiting for Feature Group Creation')\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get('FeatureGroupStatus')\n",
    "    if status != 'Created':\n",
    "        raise RuntimeError(f'Failed to create feature group {feature_group.name}')\n",
    "    print(f'FeatureGroup {feature_group.name} successfully created.')\n",
    "\n",
    "clinical_feature_group.create(\n",
    "    s3_uri = f's3://{default_s3_bucket_name}/{prefix}',\n",
    "    record_identifier_name = record_identifier_feature_name,\n",
    "    event_time_feature_name = event_time_feature_name,\n",
    "    role_arn = role,\n",
    "    enable_online_store = True\n",
    ")\n",
    "\n",
    "wait_for_feature_group_creation_complete(clinical_feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with your FeatureGroup\n",
    "### Check FeatureGroup Info\n",
    "When you create a feature group, it takes time to load the data, and you need to wait until the feature gourp is created before you can use it. You can check status using the DescirbeFeatureGroup and ListFeatureGroups APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-2:773441300604:feature-group/clinical-feature-group-02-18-50-36',\n",
       " 'FeatureGroupName': 'clinical-feature-group-02-18-50-36',\n",
       " 'RecordIdentifierFeatureName': 'patient_id',\n",
       " 'EventTimeFeatureName': 'event_time',\n",
       " 'FeatureDefinitions': [{'FeatureName': 'patient_id', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'age', 'FeatureType': 'Fractional'},\n",
       "  {'FeatureName': 'anaemia', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'creatinine_phosphokinase', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'diabetes', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'ejection_fraction', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'high_blood_pressure', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'platelets', 'FeatureType': 'Fractional'},\n",
       "  {'FeatureName': 'serum_creatinine', 'FeatureType': 'Fractional'},\n",
       "  {'FeatureName': 'serum_sodium', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'sex', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'smoking', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'time', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'DEATH_EVENT', 'FeatureType': 'Integral'},\n",
       "  {'FeatureName': 'event_time', 'FeatureType': 'Fractional'}],\n",
       " 'CreationTime': datetime.datetime(2021, 11, 2, 18, 51, 22, 827000, tzinfo=tzlocal()),\n",
       " 'OnlineStoreConfig': {'EnableOnlineStore': True},\n",
       " 'OfflineStoreConfig': {'S3StorageConfig': {'S3Uri': 's3://sagemaker-us-east-2-773441300604/feature_store_demo',\n",
       "   'ResolvedOutputS3Uri': 's3://sagemaker-us-east-2-773441300604/feature_store_demo/773441300604/sagemaker/us-east-2/offline-store/clinical-feature-group-02-18-50-36-1635879082/data'},\n",
       "  'DisableGlueTableCreation': False,\n",
       "  'DataCatalogConfig': {'TableName': 'clinical-feature-group-02-18-50-36-1635879082',\n",
       "   'Catalog': 'AwsDataCatalog',\n",
       "   'Database': 'sagemaker_featurestore'}},\n",
       " 'RoleArn': 'arn:aws:iam::773441300604:role/service-role/AmazonSageMaker-ExecutionRole-20211102T144581',\n",
       " 'FeatureGroupStatus': 'Created',\n",
       " 'ResponseMetadata': {'RequestId': '3e65a7d9-72f5-4d47-985d-7427bd594a7f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3e65a7d9-72f5-4d47-985d-7427bd594a7f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2231',\n",
       "   'date': 'Tue, 02 Nov 2021 18:51:43 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_feature_group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupSummaries': [{'FeatureGroupName': 'clinical-feature-group-02-18-50-36',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-2:773441300604:feature-group/clinical-feature-group-02-18-50-36',\n",
       "   'CreationTime': datetime.datetime(2021, 11, 2, 18, 51, 22, 827000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created'},\n",
       "  {'FeatureGroupName': 'clinical-feature-group-02-18-25-30',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-2:773441300604:feature-group/clinical-feature-group-02-18-25-30',\n",
       "   'CreationTime': datetime.datetime(2021, 11, 2, 18, 25, 31, 328000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created',\n",
       "   'OfflineStoreStatus': {'Status': 'Active'}}],\n",
       " 'ResponseMetadata': {'RequestId': 'be30cd79-c652-4c04-bb7d-a3e431c25ca6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'be30cd79-c652-4c04-bb7d-a3e431c25ca6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '530',\n",
       "   'date': 'Tue, 02 Nov 2021 18:51:55 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use boto client to list FeatureGroups\n",
    "sagemaker_client.list_feature_groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Records into the Feature Store\n",
    "After the FeatureGroups have been created, we can put data into the FeatureGroups by using the **PutRecord API**. This API can handle high TPS and is designed to be called by different streams. The data from all the these Put requests is buffered and written to S3 in chunks. the files will be written to the offline store within a few minutes of ingestion. You can use the ingest funciton to load your feature data. You pass in a data frame of feature data, set the number of workers, and choose to wait for it to return or not. For this example, to accelerate the ingestion process, we are specifying multiple workers to do the job simultaneouly. It will take <1min to ingest data to the Clinical FeatureGroup we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='clinical-feature-group-02-18-50-36', sagemaker_fs_runtime_client_config=<botocore.config.Config object at 0x7f2508da83d0>, max_workers=3, max_processes=1, _async_result=<multiprocess.pool.MapResult object at 0x7f2504399990>, _processing_pool=<pool ProcessPool(ncpus=1)>, _failed_indices=[])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_feature_group.ingest(\n",
    "    data_frame = clinical_df, \n",
    "    max_workers = 3, \n",
    "    wait = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Records from a FeatureGroup\n",
    "We can use the get_record funciton to retrieve the data for a specific record by its record identifier from the online store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '801a49fb-46d5-4cc8-96f9-f38bf5bbfcee',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '801a49fb-46d5-4cc8-96f9-f38bf5bbfcee',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '789',\n",
       "   'date': 'Tue, 02 Nov 2021 18:52:55 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Record': [{'FeatureName': 'patient_id', 'ValueAsString': '200'},\n",
       "  {'FeatureName': 'age', 'ValueAsString': '63.0'},\n",
       "  {'FeatureName': 'anaemia', 'ValueAsString': '1'},\n",
       "  {'FeatureName': 'creatinine_phosphokinase', 'ValueAsString': '1767'},\n",
       "  {'FeatureName': 'diabetes', 'ValueAsString': '0'},\n",
       "  {'FeatureName': 'ejection_fraction', 'ValueAsString': '45'},\n",
       "  {'FeatureName': 'high_blood_pressure', 'ValueAsString': '0'},\n",
       "  {'FeatureName': 'platelets', 'ValueAsString': '73000.0'},\n",
       "  {'FeatureName': 'serum_creatinine', 'ValueAsString': '0.7'},\n",
       "  {'FeatureName': 'serum_sodium', 'ValueAsString': '137'},\n",
       "  {'FeatureName': 'sex', 'ValueAsString': '1'},\n",
       "  {'FeatureName': 'smoking', 'ValueAsString': '0'},\n",
       "  {'FeatureName': 'time', 'ValueAsString': '186'},\n",
       "  {'FeatureName': 'DEATH_EVENT', 'ValueAsString': '0'},\n",
       "  {'FeatureName': 'event_time', 'ValueAsString': '1635879006.0'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_identifier_value = str(200)\n",
    "featurestore_runtime.get_record(\n",
    "    FeatureGroupName=clinical_feature_group_name,\n",
    "    RecordIdentifierValueAsString=record_identifier_value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate hive DDL Commands\n",
    "The SageMaker Python SDK's FeatureStore class also provides the functionality to generate Hive DDL commands. the schema of the table is generated based on the feature definitions. Columns are named after feature naem and data-type are inferred based on feature type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTERNAL TABLE IF NOT EXISTS sagemaker_featurestore.clinical-feature-group-02-18-50-36 (\n",
      "  patient_id STRING\n",
      "  age FLOAT\n",
      "  anaemia INT\n",
      "  creatinine_phosphokinase INT\n",
      "  diabetes INT\n",
      "  ejection_fraction INT\n",
      "  high_blood_pressure INT\n",
      "  platelets FLOAT\n",
      "  serum_creatinine FLOAT\n",
      "  serum_sodium INT\n",
      "  sex INT\n",
      "  smoking INT\n",
      "  time INT\n",
      "  DEATH_EVENT INT\n",
      "  event_time FLOAT\n",
      "  write_time TIMESTAMP\n",
      "  event_time TIMESTAMP\n",
      "  is_deleted BOOLEAN\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "  STORED AS\n",
      "  INPUTFORMAT 'parquet.hive.DeprecatedParquetInputFormat'\n",
      "  OUTPUTFORMAT 'parquet.hive.DeprecatedParquetOutputFormat'\n",
      "LOCATION 's3://sagemaker-us-east-2-773441300604/feature_store_demo/773441300604/sagemaker/us-east-2/offline-store/clinical-feature-group-02-18-50-36-1635879082/data'\n"
     ]
    }
   ],
   "source": [
    "print(clinical_feature_group.as_hive_ddl())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the data to appear in the offline store before moving forward to createing a dataset. This will take approximately 5 minutes. SageMaker FeatureStore adds metadata for each record that's ingested into the oflfine store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting fot data in offline store...\n",
      "\n",
      "Waiting fot data in offline store...\n",
      "\n",
      "Waiting fot data in offline store...\n",
      "\n",
      "Waiting fot data in offline store...\n",
      "\n",
      "Data available\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3', region_name = region)\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "clinical_feature_group_resolved_output_s3_uri = clinical_feature_group.describe().get('OfflineStoreConfig').get('DataCatalogConfig').get('TableName')\n",
    "\n",
    "clinical_feature_group_s3_prefix = prefix + '/' + account_id + '/sagemaker/' + region + '/offline-store/' + clinical_feature_group_resolved_output_s3_uri + '/data'\n",
    "\n",
    "offline_store_contents = None\n",
    "while (offline_store_contents is None):\n",
    "    objects_in_bucket = s3_client.list_objects(Bucket=default_s3_bucket_name, Prefix=clinical_feature_group_s3_prefix)\n",
    "    if ('Contents' in objects_in_bucket and len(objects_in_bucket['Contents']) >= 1):\n",
    "        offline_store_contents = objects_in_bucket['Contents']\n",
    "    else:\n",
    "        print('Waiting fot data in offline store...\\n')\n",
    "        sleep(60)\n",
    "    \n",
    "print('Data available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Training Dataset\n",
    "SageMaker FeatureStore automatically builds an AWS Glue data catalog when you create feature groups and you can turn this off if you want. We will create a training dataset with FeatureValues form the clinical FeatureGroup. This is down by utilizing the auto-built Catalog. We run an Athena query that does a simple select all in the offline store in S3 from the FeatureGroup.\n",
    "\n",
    "For model testing purpose, we'll leave out 9 records when creating the training dataset, so that we can use those 9 records as test data for after model training. You can also do a train/test split.\n",
    "\n",
    "athena_query() - Create an AthenaQuery instance\n",
    "https://sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html#sagemaker.feature_store.feature_group.AthenaQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clinical-feature-group-02-18-50-36-1635879082'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_query = clinical_feature_group.athena_query()\n",
    "clinical_table = clinical_query.table_name\n",
    "clinical_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>death_event</th>\n",
       "      <th>event_time</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>185000.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>1.635879e+09</td>\n",
       "      <td>2021-11-02 18:57:30.618</td>\n",
       "      <td>2021-11-02 18:52:09.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.18</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1.635879e+09</td>\n",
       "      <td>2021-11-02 18:57:30.618</td>\n",
       "      <td>2021-11-02 18:52:10.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>737</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1.635879e+09</td>\n",
       "      <td>2021-11-02 18:57:30.618</td>\n",
       "      <td>2021-11-02 18:52:10.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1.635879e+09</td>\n",
       "      <td>2021-11-02 18:57:30.618</td>\n",
       "      <td>2021-11-02 18:52:10.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>481000.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1.635879e+09</td>\n",
       "      <td>2021-11-02 18:57:30.547</td>\n",
       "      <td>2021-11-02 18:52:09.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id   age  anaemia  creatinine_phosphokinase  diabetes  \\\n",
       "0         231  70.0        0                        93         0   \n",
       "1          92  42.0        0                       582         0   \n",
       "2         120  60.0        1                       737         0   \n",
       "3         168  65.0        0                       582         1   \n",
       "4         212  78.0        0                       224         0   \n",
       "\n",
       "   ejection_fraction  high_blood_pressure  platelets  serum_creatinine  \\\n",
       "0                 35                    0  185000.00              1.10   \n",
       "1                 60                    0  263358.03              1.18   \n",
       "2                 60                    1  210000.00              1.50   \n",
       "3                 40                    0  270000.00              1.00   \n",
       "4                 50                    0  481000.00              1.40   \n",
       "\n",
       "   serum_sodium  sex  smoking  time  death_event    event_time  \\\n",
       "0           134    1        1   208            0  1.635879e+09   \n",
       "1           137    0        0    82            0  1.635879e+09   \n",
       "2           135    1        1    95            0  1.635879e+09   \n",
       "3           138    0        0   140            0  1.635879e+09   \n",
       "4           138    1        1   192            0  1.635879e+09   \n",
       "\n",
       "                write_time      api_invocation_time  is_deleted  \n",
       "0  2021-11-02 18:57:30.618  2021-11-02 18:52:09.000       False  \n",
       "1  2021-11-02 18:57:30.618  2021-11-02 18:52:10.000       False  \n",
       "2  2021-11-02 18:57:30.618  2021-11-02 18:52:10.000       False  \n",
       "3  2021-11-02 18:57:30.618  2021-11-02 18:52:10.000       False  \n",
       "4  2021-11-02 18:57:30.547  2021-11-02 18:52:09.000       False  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Athena query, left out 9 data for testing\n",
    "query_string = 'SELECT * FROM \"' + clinical_table + '\" LIMIT 290'\n",
    "\n",
    "# run Athena query. The output is loaded to a Pandas dataframe\n",
    "dataset = pd.DataFrame()\n",
    "clinical_query.run(query_string=query_string, output_location='s3://'+default_s3_bucket_name+'/'+prefix+'/query_results/')\n",
    "clinical_query.wait()\n",
    "# download the result of the current query and load it into DataFrame\n",
    "dataset = clinical_query.as_dataframe()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77, 81, 91, 123, 124, 201, 250, 252, 276]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which id is not in the DataFrame\n",
    "id_for_test = []\n",
    "for i in range(299):\n",
    "    if i not in dataset['patient_id'].unique():\n",
    "        id_for_test.append(i)\n",
    "id_for_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-773441300604/feature_store_demo/query_results/23851f8c-0dd8-4233-8d9b-1a4cf14754e4.csv\n"
     ]
    }
   ],
   "source": [
    "# Get execution status of the current query\n",
    "query_execution = clinical_query.get_query_execution()\n",
    "query_result = 's3://'+default_s3_bucket_name+'/'+prefix+'/query_results/'+query_execution['QueryExecution']['QueryExecutionId']+'.csv'\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select usefule columns for training with target column as the first column\n",
    "dataset = dataset[['death_event', 'age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', \n",
    "                   'ejection_fraction', 'high_blood_pressure', 'platelets', 'serum_creatinine',\n",
    "                   'serum_sodium', 'sex', 'smoking', 'time']]\n",
    "\n",
    "# write to csv in S3 withouth headers and index column\n",
    "dataset.to_csv('data/dataset.csv', header=False, index=False)\n",
    "s3_client.upload_file('data/dataset.csv', default_s3_bucket_name, prefix+'/training_input/dataset.csv')\n",
    "dataset_uri_prefix = 's3://'+default_s3_bucket_name+'/'+prefix+'/training_input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>death_event</th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>185000.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.18</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>737</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>481000.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   death_event   age  anaemia  creatinine_phosphokinase  diabetes  \\\n",
       "0            0  70.0        0                        93         0   \n",
       "1            0  42.0        0                       582         0   \n",
       "2            0  60.0        1                       737         0   \n",
       "3            0  65.0        0                       582         1   \n",
       "4            0  78.0        0                       224         0   \n",
       "\n",
       "   ejection_fraction  high_blood_pressure  platelets  serum_creatinine  \\\n",
       "0                 35                    0  185000.00              1.10   \n",
       "1                 60                    0  263358.03              1.18   \n",
       "2                 60                    1  210000.00              1.50   \n",
       "3                 40                    0  270000.00              1.00   \n",
       "4                 50                    0  481000.00              1.40   \n",
       "\n",
       "   serum_sodium  sex  smoking  time  \n",
       "0           134    1        1   208  \n",
       "1           137    0        0    82  \n",
       "2           135    1        1    95  \n",
       "3           138    0        0   140  \n",
       "4           138    1        1   192  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Deploy the Model\n",
    "We will use a SageMaker built-in algorithm, XGBoost, to predict if a patient is likely to have a heart failure.\n",
    "\n",
    "sagemaker.image_uris.retrieve() - Retrieves the ECR URI for the Docker image matching the given arguments.\n",
    "https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html?highlight=Sagemaker.image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = sagemaker.image_uris.retrieve('xgboost', region, '1.0-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sagemkaer.estimator.Estimator() - A generic Estimator to train using any supplied algorithm.\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html?highlight=Sagemaker.estimator#sagemaker.estimator.Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_path = 's3://' + default_s3_bucket_name + '/' + prefix + '/training-output'\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "training_model = Estimator(\n",
    "    training_image,     # Container image to use for training\n",
    "    role,               # An AWS IAM role\n",
    "    instance_count=1,   # Number of Amazon EC2 instances to use for training\n",
    "    instance_type='ml.m5.2xlarge',  # Type of EC2 instance to use for training\n",
    "    volumn_size=5,      # Size in GB of the EBS volume to use for storing input data during training\n",
    "    max_run=3600,  # Timeout in seconds for training. SageMaker terminates the job after this amount of time\n",
    "    input_mode='File',  # The input mode that the algorithm support\n",
    "    output_path=training_output_path,        # S3 location for saving the training result\n",
    "    sagemaker_session=feature_store_session  # Specify session object\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use default hyperparameter because we are not trying to get the best result\n",
    "training_model.set_hyperparameters(objective='binary:logistic',\n",
    "                                   num_round=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify training dataset to the dataset we just created\n",
    "\n",
    "sagemaker.inputs.TrainingInput() - Create a definition for input data used by an SageMaker training job.\n",
    "https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html?highlight=Sagemaker.inputs#sagemaker.inputs.TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    dataset_uri_prefix,       # Location of S3 data\n",
    "    distribution='FullyReplicated',  # Valid values: ‘FullyReplicated’, ‘ShardedByS3Key’\n",
    "    content_type='text/csv',  # MIME type of the input data\n",
    "    s3_data_type='S3Prefix'   # If ‘S3Prefix’, s3_data defines a prefix of s3 objects to train on\n",
    ")\n",
    "\n",
    "data_channels = {'train': train_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-02 19:00:53 Starting - Starting the training job...\n",
      "2021-11-02 19:00:55 Starting - Launching requested ML instancesProfilerReport-1635879653: InProgress\n",
      "...\n",
      "2021-11-02 19:01:50 Starting - Preparing the instances for training............\n",
      "2021-11-02 19:03:50 Downloading - Downloading input data\n",
      "2021-11-02 19:03:50 Training - Downloading the training image...\n",
      "2021-11-02 19:04:25 Uploading - Uploading generated training model\n",
      "2021-11-02 19:04:25 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[19:04:08] 290x12 matrix with 3480 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 290 rows\u001b[0m\n",
      "\u001b[34m[19:04:08] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.07931\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.07241\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.06552\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.04483\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.03448\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.03448\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.02414\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.02069\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.01724\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.01379\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.02069\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.01035\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.01035\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.00690\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.00690\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.00345\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.00690\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.00345\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.00000\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.00000\u001b[0m\n",
      "Training seconds: 37\n",
      "Billable seconds: 37\n"
     ]
    }
   ],
   "source": [
    "training_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Hosing for the Model\n",
    "Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint. this will allow us to make predictions (or inference) form the model. The endpoint deployment can be accomplished as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "predictor = training_model.deploy(initial_instance_count=1, instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker FeatureStore During Inference\n",
    "SageMaker FeatureStore can be useful in supplementing data for inference requests because of the low-latency GetRecord functionality. For this demo, we will be given a patientID and query our online FeatureGroup to build our inference requests.\n",
    "From the patient ID we left out in training set, we can choose one patient ID to test the real-time reference. In this example we choose patient 276."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77, 81, 91, 123, 124, 201, 250, 252, 276]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_for_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the data for a specific feature by its record identifier (patient ID randomly chosen from test set) from the online store, we can use the get_record function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'FeatureName': 'patient_id', 'ValueAsString': '276'},\n",
       " {'FeatureName': 'age', 'ValueAsString': '70.0'},\n",
       " {'FeatureName': 'anaemia', 'ValueAsString': '0'},\n",
       " {'FeatureName': 'creatinine_phosphokinase', 'ValueAsString': '618'},\n",
       " {'FeatureName': 'diabetes', 'ValueAsString': '0'},\n",
       " {'FeatureName': 'ejection_fraction', 'ValueAsString': '35'},\n",
       " {'FeatureName': 'high_blood_pressure', 'ValueAsString': '0'},\n",
       " {'FeatureName': 'platelets', 'ValueAsString': '327000.0'},\n",
       " {'FeatureName': 'serum_creatinine', 'ValueAsString': '1.1'},\n",
       " {'FeatureName': 'serum_sodium', 'ValueAsString': '142'},\n",
       " {'FeatureName': 'sex', 'ValueAsString': '0'},\n",
       " {'FeatureName': 'smoking', 'ValueAsString': '0'},\n",
       " {'FeatureName': 'time', 'ValueAsString': '245'},\n",
       " {'FeatureName': 'DEATH_EVENT', 'ValueAsString': '0'},\n",
       " {'FeatureName': 'event_time', 'ValueAsString': '1635879006.0'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_id = str(276)\n",
    "\n",
    "# Helper to parse the feature value form the record\n",
    "def get_feature_value(record, feature_name):\n",
    "    return str(list(filter(lambda r: r['FeatureName'] == feature_name, record))[0]['ValueAsString'])\n",
    "\n",
    "clinical_response = featurestore_runtime.get_record(FeatureGroupName=clinical_feature_group_name,\n",
    "                                                     RecordIdentifierValueAsString=patient_id)\n",
    "clinical_record = clinical_response['Record']\n",
    "clinical_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we choose the feature value from the retrieved feature list, exclude the record identifier id, the event time, and the target variable, and build a list of values as the input to the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_request = [\n",
    "    get_feature_value(clinical_record, 'age'),\n",
    "    get_feature_value(clinical_record, 'anaemia'),\n",
    "    get_feature_value(clinical_record, 'creatinine_phosphokinase'),\n",
    "    get_feature_value(clinical_record, 'diabetes'),\n",
    "    get_feature_value(clinical_record, 'ejection_fraction'),\n",
    "    get_feature_value(clinical_record, 'high_blood_pressure'),\n",
    "    get_feature_value(clinical_record, 'platelets'),\n",
    "    get_feature_value(clinical_record, 'serum_creatinine'),\n",
    "    get_feature_value(clinical_record, 'serum_sodium'),\n",
    "    get_feature_value(clinical_record, 'sex'),\n",
    "    get_feature_value(clinical_record, 'smoking'),\n",
    "    get_feature_value(clinical_record, 'time'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01355772279202938\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "results = predictor.predict(','.join(inference_request), initial_args = {'ContentType': 'text/csv'})\n",
    "prediction = json.loads(results)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Predictor will call the hosted model and give a prediction result. The model predicts the patient 276 is not likely (1.36%) to experience a death event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "Need to delete the feature group and endpoint. Otherwise it will remain there, produce cost and fill up the available spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"FeatureGroupSummaries\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# uncomment the following code to delete the feature group\n",
    "clinical_feature_group.delete()\n",
    "\n",
    "# use aws command line to check if the feature group is deleted\n",
    "!aws sagemaker list-feature-groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Endpoints\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()\n",
    "\n",
    "!aws sagemaker list-endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these aws command line to delete unused feature group and endpoint\n",
    "# !aws sagemaker delete-feature-group --feature-group-name clinical-feature-group-02-18-25-30\n",
    "# !aws sagemaker delete-endpoint --endpoint-name sagemaker-xgboost-2021-11-02-19-08-25-428"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
